# urllib을 활용한 웹 데이터 추출(1)

##### anaconda prompt

```markdown
activate section2
atom 
=> 아톰 열기
```



##### atom

```python
print('hi')
print('한글') #실행 => 한글은 깨져서 나옴

# 이때, anaconda prompt 에서
# python 
# 	print('한글')  => 한글이 출력됨

import sys
import io

sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding = 'utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding = 'utf-8')

print('한글')
print('하이') # import해서 위와 같이 설정해주면 한글이 나옴 
```



##### chrome

```markdown
ex)
1. chrome -> Naver -> '동물'검색 -> 이미지주소복사 -> 새탭 -> 주소붙여넣기
2. chrome -> Naver -> '동물'검색 -> F12 -> select버튼 클릭 -> 원하는 이미지 클릭 -> Element -> 이미지속성과 scr에 이미지주소가 뜸 -> 주소 복사 -> 새탭 -> 주소붙여넣기
```



##### img저장 

```python
import urllib.request # imgUrl 사용하기위해

# 이미지 주소 
imgUrl = "http://blogfiles.naver.net/20120717_72/sunjahwang_1342512929146R1wSv_JPEG/%B5%BF%B9%B00_%28411%29.jpg"

# savePath에 경로설정 
savePath = "C:/Users/student/selfstudy/웹 크롤링을 활용한 다양한 자동화 APP/jihyeonselfstudy/section2/test1.jpg"

urllib.request.urlretrieve(imgUrl, savePath) # savePath 경로에 따라 이미지 저장

print("다운로드 완료!")
```



##### html 저장 

```python
import urllib.request as dw # dw를 사용하게 되면 이렇게!

htmlURL = "http://google.com"
savePath2 = "C:/Users/student/selfstudy/웹 크롤링을 활용한 다양한 자동화 APP/jihyeonselfstudy/section2/index.html"


dw.urlretrieve(htmlURL, savePath2)
print("다운로드 완료!")

```



##### 또 다른 방법 

```python
import urllib.request as dw

imgUrl = "http://blogfiles.naver.net/20120717_72/sunjahwang_1342512929146R1wSv_JPEG/%B5%BF%B9%B00_%28411%29.jpg"
htmlURL = "http://google.com"

savePath1 = "C:/Users/student/selfstudy/웹 크롤링을 활용한 다양한 자동화 APP/jihyeonselfstudy/section2/test1.jpg"
savePath2 = "C:/Users/student/selfstudy/웹 크롤링을 활용한 다양한 자동화 APP/jihyeonselfstudy/section2/index.html"

f = dw.urlopen(imgUrl).read()
f2 = dw.urlopen(htmlURL).read()
saveFile1 = open(savePath1, 'wb') # w: write r:read a:add(파일의 끝부분부터 데이터 추가)
saveFile1.write(f) 
saveFile1.close() #1번쨰방법

with open(savePath2, 'wb') ad saveFile2: #2번째방법(권장) 
    saveFile2.write(f2)
    
print("다운로드 완료!")

```



###### 비교

```markdown
urlretrieve: 저장 -> open('r') -> 변수할당 -> 파싱 -> 저장

urlopen: (저장 전)변수 할당 -> 파싱 -> 저장 
```

